{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.optim import Adam,SGD\n",
    "import numpy as np\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(\n",
    "                        [[[[1,2,3,4],[2,3,4,5],[5,6,7,8],[1,3,4,5]]],\n",
    "                        [[[-1,2,3,-4],[2,-3,4,5],[-5,6,-7,8],[-1,-3,-4,-5]]]]\n",
    "                       ).to(device).float()\n",
    "X_train /= 8    \n",
    "y_train = torch.tensor([0,1],dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 1, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(1,1),\n",
    "        nn.Sigmoid()\n",
    "    ).to(device)\n",
    "    loss=nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "    return model,loss,optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 1, 2, 2]             10\n",
      "├─MaxPool2d: 1-2                         [-1, 1, 1, 1]             --\n",
      "├─ReLU: 1-3                              [-1, 1, 1, 1]             --\n",
      "├─Flatten: 1-4                           [-1, 1]                   --\n",
      "├─Linear: 1-5                            [-1, 1]                   2\n",
      "├─Sigmoid: 1-6                           [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model,loss,optimizer = get_model()\n",
    "summary(model, X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, loss, optimizer, X_batch, y_batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_batch)\n",
    "    loss_value = loss(y_pred.view(-1), y_batch)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(TensorDataset(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    for X_batch, y_batch in trn_dl:\n",
    "        loss_value = train_batch(model, loss, optimizer, X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1493]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Toy example just to showcase how it works, not that its a generalizable implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Flatten(start_dim=1, end_dim=-1),\n",
       " Linear(in_features=1, out_features=1, bias=True),\n",
       " Sigmoid()]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cnn_w, cnn_b), (lin_w, lin_b) = [(layer.weight.data,layer.bias.data) for layer in list(model.children()) if hasattr(layer, 'weight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_im, w_img = X_train.shape[-2:]\n",
    "h_cnn, w_cnn = cnn_w.shape[-2:]\n",
    "sumprod=torch.zeros(h_im-h_cnn+1,w_img-w_cnn+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(h_im-h_cnn+1):\n",
    "    for j in range(w_img-w_cnn+1):\n",
    "        sumprod[i,j] = torch.sum(X_train[0,0,i:i+h_cnn,j:j+w_cnn]*cnn_w.reshape(3,3))+cnn_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer_output=torch.max(sumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer_output.clamp_min_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = pooling_layer_output*lin_w+lin_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1493]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
